{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descriptor Calculation for Reference Sets\n",
    "\n",
    "This Notebooks precalculates and saves a set of descriptors for the 3 reference sets listed below.\n",
    "\n",
    "All data sets were standardized and deduplicated (by the InChIKeys of the parent structures) using the `stand_struct.py` script from the `python_scripts/` folder.  \n",
    "The actual external data sets are not included in this repository.\n",
    "\n",
    "### Enamine Advanced Screenin\n",
    "\n",
    "The Enamine Advanced Screening collection was downloaded from the Enamine home page on 04-Dec-2020 ([link](https://enamine.net/compound-collections/screening-collection/advanced-collection)).  \n",
    "After standardization and deduplication, it contained 526897 compounds.  \n",
    "\n",
    "`$ stand_struct enamine_adv.sdf full` \n",
    "\n",
    "For the Enamine data set, a random subset of 50000 structures was chosen, after sorting by `NumHA`.\n",
    "\n",
    "### DrugBank Approved and Investigational\n",
    "\n",
    "The subsets of approved and investigational drugs were downloaded from DrugBank (v5.1.8, [link](https://go.drugbank.com/releases)).  \n",
    "The two files were standardized and deduplicated into one data set:\n",
    "\n",
    "`stand_struct drugbank_5_1_8_appr.sdf,drugbank_5_1_8_inv.sdf full`\n",
    "\n",
    "The resulting data set contained 4866 entries:\n",
    "\n",
    "### ChEMBL Natural Products (ChEMBL NPs)\n",
    "\n",
    "A download of the SDF version of ChEMBL v30 ([link](https://ftp.ebi.ac.uk/pub/databases/chembl/ChEMBLdb/latest/chembl_30.sdf.gz)) was downloaded and processed into the standardized form (deduplication, no canonicalization):\n",
    "\n",
    "`$ stand_struct chembl_30.sdf.gz full --nocanon`\n",
    "\n",
    "The generated file `chembl_v30_full_nocanon.tsv` contained 2027851 entries.\n",
    "\n",
    "The list of ChEMBL_IDs for the ChEMBL Natural Products set was extracted by applying the `extract_nps_from_sqlite.py` script to the downladed version SQLITE of ChEMBL v30 ([linl](https://ftp.ebi.ac.uk/pub/databases/chembl/ChEMBLdb/latest/chembl_30_sqlite.tar.gz)). The script then merged the Smiles from the `chembl_v30_full_nocanon.tsv` file and applied a deglycosylation.\n",
    "\n",
    "The final ChEMBL NP data set contained 45679 entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "def warn(*args, **kwargs):\n",
    "    pass  # to silence scikit-learn warnings\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.warn = warn\n",
    "\n",
    "# Type hints\n",
    "from typing import Iterable, List, Set, Dict, Union, Optional\n",
    "\n",
    "# Global Imports\n",
    "# from collections import Counter\n",
    "# import glob\n",
    "\n",
    "import pandas as pd\n",
    "# import numpy as np\n",
    "# from scipy.stats import median_absolute_deviation as mad\n",
    "\n",
    "from rdkit import DataStructs\n",
    "from rdkit.Chem import AllChem as Chem, QED\n",
    "from rdkit.Chem import Descriptors as Desc\n",
    "from rdkit.Chem import rdMolDescriptors as rdMolDesc\n",
    "from rdkit.Chem import Fragments\n",
    "# from rdkit.Chem import Draw\n",
    "# from rdkit.Chem.Draw import IPythonConsole\n",
    "\n",
    "from Contrib.NP_Score import npscorer\n",
    "\n",
    "# from mol_frame import mol_frame as mf\n",
    "# from cellpainting3 import processing as cpp, tools as cpt\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# Project-local Imports\n",
    "from jupy_tools import plt_style\n",
    "from jupy_tools import utils as u, mol_view as mv\n",
    "from jupy_tools.utils import info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_EN = \"enamine_adv_full\"\n",
    "DATA_DB = \"drugbank_5.1.8_appr_inv_full\"\n",
    "DATA_NP = \"chembl_30_np_full_nocanon_deglyco\"\n",
    "\n",
    "fscore = npscorer.readNPModel()\n",
    "def score_np(mol):\n",
    "    return npscorer.scoreMol(mol, fscore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enamine Screening Library\n",
    "# After calculating NumHA, the subset is generated\n",
    "df_en = u.read_tsv(f\"/home/pahl/comas/notebooks/sdf/enamine/{DATA_EN}.tsv\")\n",
    "\n",
    "# DrugBank Approved and Investigation Drugs\n",
    "df_db = u.read_tsv(f\"/home/pahl/comas/notebooks/sdf/drugbank/{DATA_DB}.tsv\")\n",
    "\n",
    "# NPs from ChEMBL 30\n",
    "df_np = u.read_tsv(f\"/home/pahl/comas/notebooks/sdf/chembl30/{DATA_NP}.tsv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Descriptor Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptors = {\n",
    "    \"NP_Like\": lambda x: round(score_np(x), 2), \n",
    "    \"QED\": lambda x: round(QED.default(x), 3),\n",
    "    \"NumHA\": lambda x: x.GetNumAtoms(),\n",
    "    \"MW\": lambda x: round(Desc.ExactMolWt(x), 2),\n",
    "    \"NumRings\": rdMolDesc.CalcNumRings,\n",
    "    \"NumRingsArom\": rdMolDesc.CalcNumAromaticRings,\n",
    "    \"NumRingsAli\": rdMolDesc.CalcNumAliphaticRings,\n",
    "    \"NumHDon\": rdMolDesc.CalcNumLipinskiHBD,\n",
    "    \"NumHAcc\": rdMolDesc.CalcNumLipinskiHBA,\n",
    "    \"LogP\": lambda x: round(Desc.MolLogP(x), 2),\n",
    "    \"TPSA\": lambda x: round(rdMolDesc.CalcTPSA(x), 2),\n",
    "    \"NumRotBd\": rdMolDesc.CalcNumRotatableBonds,\n",
    "    \"NumAtOx\": lambda x: len(\n",
    "        [a for a in x.GetAtoms() if a.GetAtomicNum() == 8]\n",
    "    ),\n",
    "    \"NumAtN\": lambda x: len(\n",
    "        [a for a in x.GetAtoms() if a.GetAtomicNum() == 7]\n",
    "    ),\n",
    "    \"NumAtHal\": Fragments.fr_halogen,\n",
    "    \"NumAtBridgehead\": rdMolDesc.CalcNumBridgeheadAtoms,\n",
    "    \"FCsp3\": lambda x: round(rdMolDesc.CalcFractionCSP3(x), 3), \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enamine\n",
    "desc = \"NumHA\"\n",
    "df_en = u.calc_from_smiles(df_en, desc, descriptors[desc])\n",
    "df_en = df_en.sort_values(by=desc, ascending=False)\n",
    "df_en = df_en.sample(n=50000, random_state=0xc0ffee)\n",
    "\n",
    "for desc in descriptors:\n",
    "    if desc == \"NumHA\":\n",
    "        continue  # was already calculated above\n",
    "    print(f\"{desc:15}: \")\n",
    "    df_en = u.calc_from_smiles(df_en, desc, descriptors[desc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DrugBank\n",
    "for desc in descriptors:\n",
    "    print(f\"{desc:15}: \")\n",
    "    df_db = u.calc_from_smiles(df_db, desc, descriptors[desc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ChEMBL NPs\n",
    "for desc in descriptors:\n",
    "    print(f\"{desc:15}: \")\n",
    "    df_np = u.calc_from_smiles(df_np, desc, descriptors[desc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following files are not included in the repository:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u.write_tsv(df_en, f\"input/{DATA_EN}_sample_50k_desc.tsv\")  # 50000 entries\n",
    "u.write_tsv(df_db, f\"input/{DATA_DB}_desc.tsv\")  # 4866 entries\n",
    "u.write_tsv(df_np, f\"input/{DATA_NP}_desc.tsv\")  # 45679 entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "nav_menu": {},
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
